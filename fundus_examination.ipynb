{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza statystyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConfusionMatrix(processed_image, result_image):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "\n",
    "    confusion_matrix_image = np.zeros((processed_image.shape[0], processed_image.shape[1], 3), np.uint8)\n",
    "    \n",
    "    for i in range(len(processed_image)):\n",
    "        for j in range(len(processed_image[0])):\n",
    "            \n",
    "            if processed_image[i][j] == 0 and result_image[i][j] == False:\n",
    "                TN += 1\n",
    "            elif processed_image[i][j] == 0 and result_image[i][j] == True:\n",
    "                FN += 1\n",
    "                confusion_matrix_image[i][j] = (255, 0, 0)\n",
    "            elif processed_image[i][j] == 255 and result_image[i][j] == False:\n",
    "                FP += 1\n",
    "                confusion_matrix_image[i][j] = (0, 155, 255)\n",
    "            else:\n",
    "                TP += 1\n",
    "                confusion_matrix_image[i][j] = (255, 255, 255)\n",
    "    \n",
    "    return TP, TN, FP, FN, confusion_matrix_image\n",
    "\n",
    "def calculateAccuracy(TP, TN, FP, FN):\n",
    "    return (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "def calculateSensitivity(TP, TN, FP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def calculateSpecificity(TP, TN, FP, FN):\n",
    "    return TN / (TN + FP)\n",
    "\n",
    "def calculatePrecision(TP, TN, FP, FN):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def calculateGMean(TP, TN, FP, FN):\n",
    "    sensitivity = calculateSensitivity(TP, TN, FP, FN)\n",
    "    specificity = calculateSpecificity(TP, TN, FP, FN)\n",
    "    \n",
    "    return np.sqrt(sensitivity * specificity)\n",
    "\n",
    "def calculateFMeasure(TP, TN, FP, FN):\n",
    "    precision = calculatePrecision(TP, TN, FP, FN)\n",
    "    sensitivity = calculateSensitivity(TP, TN, FP, FN)\n",
    "    \n",
    "    return (2 * precision * sensitivity) / (precision + sensitivity)\n",
    "\n",
    "def displayStatisticalAnalysis(processed_image, result_image):\n",
    "    TP, TN, FP, FN, confusion_matrix_image = createConfusionMatrix(processed_image, result_image)\n",
    "    \n",
    "    print(\"Accuracy:    \", calculateAccuracy(TP, TN, FP, FN))\n",
    "    print(\"Sensitivity: \", calculateSensitivity(TP, TN, FP, FN))\n",
    "    print(\"Specificity: \", calculateSpecificity(TP, TN, FP, FN))\n",
    "    print(\"Precision:   \", calculatePrecision(TP, TN, FP, FN))\n",
    "    print(\"G-Mean:      \", calculateGMean(TP, TN, FP, FN))\n",
    "    print(\"F-Measure:   \", calculateFMeasure(TP, TN, FP, FN))\n",
    "    \n",
    "    return confusion_matrix_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetwarzanie obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBuilder:\n",
    "    def __init__(self):\n",
    "        self.image = None\n",
    "        \n",
    "    def loadImage(self, image):\n",
    "        self.image = image\n",
    "        return self\n",
    "    \n",
    "    def extractGreenChannel(self):\n",
    "        b, g, r = cv.split(self.image)\n",
    "        self.image = g\n",
    "        return self\n",
    "    \n",
    "    def applyClahe(self):\n",
    "        clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        self.image = clahe.apply(self.image)\n",
    "        return self\n",
    "\n",
    "    def increaseContrast(self):\n",
    "        self.image = cv.addWeighted(self.image, 2, self.image, 0, 0)\n",
    "        return self\n",
    "\n",
    "    def toGray(self):\n",
    "        self.image = cv.cvtColor(self.image, cv.COLOR_RGB2GRAY)\n",
    "        return self\n",
    "\n",
    "    def medianBlur(self):\n",
    "        self.image = cv.medianBlur(self.image, 5)\n",
    "        return self\n",
    "    \n",
    "    def adaptiveThreshold(self):\n",
    "        self.image = cv.adaptiveThreshold(\\\n",
    "                    self.image, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 13, 2)\n",
    "        return self\n",
    "\n",
    "    def denoise(self):\n",
    "        self.image = cv.fastNlMeansDenoising(self.image, None, 3, 7, 21)\n",
    "        return self\n",
    "    \n",
    "    def denoiseByContours(self):\n",
    "        mask = np.ones([self.image.shape[0], self.image.shape[1]], dtype=\"uint8\") * 255\n",
    "        contours, _ = cv.findContours(self.image.copy(), cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            if cv.contourArea(cnt) <= 200:\n",
    "                cv.drawContours(mask, [cnt], -1, 0, -1)\n",
    "        self.image = cv.bitwise_and(self.image, self.image, mask=mask)\n",
    "        return self\n",
    "\n",
    "    def applyOpening(self, k):\n",
    "        self.image = cv.morphologyEx(self.image, cv.MORPH_OPEN, cv.getStructuringElement(cv.MORPH_ELLIPSE, (k, k)), iterations=1)\n",
    "        return self\n",
    "\n",
    "    def applyClosing(self, k):\n",
    "        self.image = cv.morphologyEx(self.image, cv.MORPH_CLOSE, cv.getStructuringElement(cv.MORPH_ELLIPSE, (k, k)), iterations=1)\n",
    "        return self\n",
    "\n",
    "    def build(self):\n",
    "        return self.image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikator KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPatches(img, patch_size):\n",
    "    return image.extract_patches_2d(img, patch_size)\n",
    "\n",
    "def calculateHuMoments(patch):\n",
    "    return cv.HuMoments(cv.moments(patch)).flatten() \n",
    "\n",
    "def calculateVariance(patch):\n",
    "    return np.var(patch)\n",
    "\n",
    "def calculateMean(patch):\n",
    "    return np.mean(patch)\n",
    "\n",
    "def getMiddlePixel(patch, patch_size):\n",
    "    return patch[patch_size[0] // 2][patch_size[1] // 2]\n",
    "\n",
    "def createFeaturesDataset(processed_image, patch_size = (5, 5)):\n",
    "    max_y, max_x = processed_image.shape\n",
    "    padding = patch_size[0] // 2  \n",
    "    padded_image = np.zeros((max_y + 2 * padding, max_x + 2 * padding))\n",
    "    padded_image[padding:-padding, padding:-padding] = processed_image\n",
    "    \n",
    "    processed_patches = extractPatches(padded_image, patch_size)    \n",
    "    x = [] \n",
    "    \n",
    "    for i in range(len(processed_patches)):\n",
    "        patch = processed_patches[i]\n",
    "\n",
    "        mean = calculateMean(patch)\n",
    "        variance = calculateVariance(patch)\n",
    "        middle_pixel = getMiddlePixel(patch, patch_size)   \n",
    "        \n",
    "        x.append(np.concatenate((mean, variance, middle_pixel), axis = None))\n",
    "    \n",
    "    return x\n",
    "\n",
    "def createDataset(processed_image, result_image, patch_size = (5, 5), step = 10):\n",
    "    processed_patches = extractPatches(processed_image, patch_size)\n",
    "    result_patches = extractPatches(result_image, patch_size)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(0, len(processed_patches), step):\n",
    "        patch = processed_patches[i]\n",
    "        \n",
    "        mean = calculateMean(patch)\n",
    "        variance = calculateVariance(patch)\n",
    "        middle_pixel = getMiddlePixel(patch, patch_size)\n",
    "        \n",
    "        x.append(np.concatenate((mean, variance, middle_pixel), axis = None))\n",
    "        y.append(result_patches[i][patch_size[0] // 2][patch_size[1] // 2]) \n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def createClassifier(processed_image, result_image):\n",
    "    x, y = createDataset(processed_image, result_image)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "    \n",
    "    undersample = RandomUnderSampler(sampling_strategy = 0.2)\n",
    "    x_train_undersample, y_train_undersample = undersample.fit_resample(x_train, y_train)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
    "    knn.fit(x_train_undersample, y_train_undersample)\n",
    "    \n",
    "#     y_pred = knn.predict(x_test)\n",
    "#     print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return knn\n",
    " \n",
    "def preprocessImage(input_image):    \n",
    "    input_image = cv.cvtColor(input_image, cv.COLOR_RGB2GRAY)\n",
    "    input_image = cv.fastNlMeansDenoising(input_image, None, 3, 7, 21)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    input_image = clahe.apply(input_image)\n",
    "    \n",
    "    return input_image\n",
    "\n",
    "def classifyImage(input_image, result_image, knn, patch_size = (5, 5)):  \n",
    "    input_image = preprocessImage(input_image)\n",
    "    x_test = createFeaturesDataset(input_image)\n",
    "    \n",
    "    return knn.predict(x_test).reshape(result_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyświetlanie wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayImages(inputImage, processedImage, result, confusion_matrix_image):\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=80)   \n",
    "    \n",
    "    ax = fig.add_subplot(221)\n",
    "    ax.set_title('Obraz wejściowy')\n",
    "    ax.imshow(inputImage, cmap = 'gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = fig.add_subplot(222)\n",
    "    ax.set_title('Maska ekspercka')\n",
    "    ax.imshow(result, cmap = 'gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = fig.add_subplot(223)\n",
    "    ax.set_title('Nasz wynik')\n",
    "    ax.imshow(processedImage, cmap = 'gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = fig.add_subplot(224)\n",
    "    ax.set_title('Macierz pomyłek')\n",
    "    ax.imshow(confusion_matrix_image, cmap = 'gray')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metody przetwarzania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageProcessing(input_image, expected_result_image):    \n",
    "    '''przetwarzanie obrazu'''\n",
    "        \n",
    "    processed_image = ImageBuilder()\\\n",
    "                    .loadImage(input_image.copy())\\\n",
    "                    .denoise()\\\n",
    "                    .increaseContrast()\\\n",
    "                    .extractGreenChannel()\\\n",
    "                    .applyClahe()\\\n",
    "                    .applyOpening(5)\\\n",
    "                    .applyClosing(5)\\\n",
    "                    .adaptiveThreshold()\\\n",
    "                    .denoiseByContours()\\\n",
    "                    .applyClosing(5)\\\n",
    "                    .build()\n",
    "       \n",
    "    confusion_matrix_image = displayStatisticalAnalysis(processed_image, expected_result_image)\n",
    "    displayImages(input_image, processed_image, expected_result_image, confusion_matrix_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifierProcessing(input_image, expected_result_image, classifier_input, classifier_result):    \n",
    "    '''klasyfikator KNN''' \n",
    "        \n",
    "    classifier_processed_image = ImageBuilder()\\\n",
    "                        .loadImage(classifier_input)\\\n",
    "                        .build()                   \n",
    "    \n",
    "    classifier_result_image = ImageBuilder()\\\n",
    "                        .loadImage(classifier_result)\\\n",
    "                        .toGray()\\\n",
    "                        .build()\n",
    "\n",
    "    classifier_processed_image = preprocessImage(classifier_processed_image)\n",
    "    \n",
    "    knn = createClassifier(classifier_processed_image, classifier_result_image)\n",
    "    knn_result_image = classifyImage(input_image, expected_result_image, knn)\n",
    "    \n",
    "    knn_confusion_matrix_image = displayStatisticalAnalysis(knn_result_image, expected_result_image)\n",
    "    displayImages(input_image, knn_result_image, expected_result_image, knn_confusion_matrix_image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Widgety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imageUpload = widgets.FileUpload(accept='image/*',\n",
    "                                       multiple=False)\n",
    "\n",
    "expected_result_imageUpload = widgets.FileUpload(accept='image/*',\n",
    "                                                 multiple=False)\n",
    "\n",
    "classifier_input_imageUpload =  widgets.FileUpload(accept='image/*',\n",
    "                                                   multiple=False)\n",
    "\n",
    "classifier_expected_result_imageUpload =  widgets.FileUpload(accept='image/*',\n",
    "                                                             multiple=False)\n",
    "\n",
    "image_processing_checkbox = widgets.Checkbox(value=False)\n",
    "classifier_processing_checkbox = widgets.Checkbox(value=False)\n",
    "\n",
    "display_box = widgets.HBox(\n",
    "    [widgets.VBox([widgets.Label('Input image'), \n",
    "                   widgets.Label('Expected result image'),\n",
    "                   widgets.Label('Classifier input image'),\n",
    "                   widgets.Label('Classifier expected result'),\n",
    "                   widgets.Label('Use image processing'), \n",
    "                   widgets.Label('Use classifier processing')]), \n",
    "     widgets.VBox([input_imageUpload, \n",
    "                   expected_result_imageUpload,\n",
    "                   classifier_input_imageUpload,\n",
    "                   classifier_expected_result_imageUpload,\n",
    "                   image_processing_checkbox, \n",
    "                   classifier_processing_checkbox])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundus examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad789a46df00482e928dd8c20fd124d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Input image'), Label(value='Expected result image'), Label(value='C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e9cb1b00454fe0ac1cebdb64aa47cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Process image', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd811d9dbac948ac8e9bb4d0eb394b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cbf4a3a7654057bdc5b0efa22bf8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    display(display_box)\n",
    "    \n",
    "    process_button = widgets.Button(description='Process image')    \n",
    "    output = widgets.Output()\n",
    "    output2 = widgets.Output()\n",
    "    display(process_button, output, output2)\n",
    "        \n",
    "    def onProcessButton(b):\n",
    "        with output:\n",
    "            for uploaded_filename in input_imageUpload.value:\n",
    "                clear_output(wait=True)\n",
    "                content = input_imageUpload.value[uploaded_filename]['content']\n",
    "                input_image = Image.open(io.BytesIO(content))\n",
    "                input_image = np.asarray(input_image)\n",
    "\n",
    "            for uploaded_filename in expected_result_imageUpload.value:\n",
    "                clear_output(wait=True)\n",
    "                content = expected_result_imageUpload.value[uploaded_filename]['content']\n",
    "                expected_result = Image.open(io.BytesIO(content))\n",
    "                expected_result = np.asarray(expected_result)\n",
    "            \n",
    "        if image_processing_checkbox.value:\n",
    "            imageProcessing(input_image, expected_result)\n",
    "            \n",
    "        if classifier_processing_checkbox.value:\n",
    "            with output:\n",
    "                for uploaded_filename in classifier_input_imageUpload.value:\n",
    "                    clear_output(wait=True)\n",
    "                    content = classifier_input_imageUpload.value[uploaded_filename]['content']\n",
    "                    classifier_input = Image.open(io.BytesIO(content))\n",
    "                    classifier_input = np.asarray(classifier_input)\n",
    "\n",
    "                for uploaded_filename in classifier_expected_result_imageUpload.value:\n",
    "                    clear_output(wait=True)\n",
    "                    content = classifier_expected_result_imageUpload.value[uploaded_filename]['content']\n",
    "                    classifier_expected_result = Image.open(io.BytesIO(content))\n",
    "                    classifier_expected_result = np.asarray(classifier_expected_result)\n",
    "                    \n",
    "            classifierProcessing(input_image, expected_result, classifier_input, classifier_expected_result)\n",
    "    \n",
    "    process_button.on_click(onProcessButton)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
